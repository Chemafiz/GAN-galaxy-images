{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97fc48bf-2b55-4c9d-b1c0-4c8e61b7ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.layers import Dense, Flatten, Reshape, Conv2D, MaxPool2D, Conv2DTranspose, BatchNormalization, Dropout, LeakyReLU\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras import activations\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from astroNN.datasets import load_galaxy10\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99be6c89-7397-499f-83c3-bc81a7786a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1922659417438655971\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4772069376\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8560587639904246472\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adf8810f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79955288-9bad-4821-bfb1-e0a3d9e57639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File('Galaxy10_DECals.h5', 'r') as h5_file:\n",
    "#     # Odczytaj dane ze zbior√≥w danych\n",
    "#     ans_data = h5_file['ans'][:]\n",
    "#     dec_data = h5_file['dec'][:]\n",
    "#     images_data = h5_file['images'][:]\n",
    "#     pxscale_data = h5_file['pxscale'][:]\n",
    "#     ra_data = h5_file['ra'][:]\n",
    "#     redshift_data = h5_file['redshift'][:]\n",
    "\n",
    "# # Tworzenie DataFrame z danymi\n",
    "# data_dict = {\n",
    "#     'ans': ans_data,\n",
    "#     'dec': dec_data,\n",
    "#     'images': images_data,\n",
    "#     'pxscale': pxscale_data,\n",
    "#     'ra': ra_data,\n",
    "#     'redshift': redshift_data\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d71983a4-4561-42b2-ac44-1d9c5932a388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.3 s, sys: 42.7 s, total: 1min 32s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# # To get the images and labels from file\n",
    "with h5py.File('../Galaxy10_DECals.h5', 'r') as F:\n",
    "    images = np.array(F['images'])\n",
    "    labels = np.array(F['ans'])\n",
    "\n",
    "# To convert the labels to categorical 10 classes\n",
    "labels = utils.to_categorical(labels, 10)\n",
    "\n",
    "# To convert to desirable type\n",
    "labels = labels.astype(np.uint8)\n",
    "images = images.astype(np.float32)\n",
    "labels_names = [\"Disturbed Galaxies\", \"Merging Galaxies\", \"Round Smooth Galaxies\", \"In-between Round Smooth Galaxies\", \"Cigar Shaped Smooth Galaxies\",\n",
    "            \"Barred Spiral Galaxies\", \"Unbarred Tight Spiral Galaxies\", \"Unbarred Loose Spiral Galaxies\", \"Edge-on Galaxies without Bulge\", \"Edge-on Galaxies with Bulge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447ae9bc-295f-40d1-ab36-0d9e4e0c481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = list(np.array_split(images, 1024))\n",
    "\n",
    "def genenerator():\n",
    "    for i in images:\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3b8acc-eb03-4d58-b39b-c3be90d9769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flow = tf.data.Dataset.from_generator(genenerator, tf.float32, output_shapes=(256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ffe8d5-3328-4563-8cec-5c68c606b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def custom_preprocessing(x):\n",
    "    x = tf.image.rgb_to_grayscale(x)  # Convert to grayscale\n",
    "    # print(x.shape)\n",
    "    # x = tf.image.resize(x, (64, 64))  # Resize to 64x64\n",
    "    # print(x.shape)\n",
    "    return x\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=custom_preprocessing,\n",
    "    rescale=1.0/127.5 - 1.0 \n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "data_flow = data_generator.flow(\n",
    "    images,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae8f6db2-c4da-40c4-bee1-b0ca4ab4e5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function resize_data at 0x7fe7e1f29a60> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function resize_data at 0x7fe7e1f29a60>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function resize_data at 0x7fe7e1f29a60> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function resize_data at 0x7fe7e1f29a60>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "CPU times: user 93.8 ms, sys: 78.9 ms, total: 173 ms\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# images = tf.data.Dataset.from_tensor_slices(images)\n",
    "\n",
    "def resize_data(image):\n",
    "  SIZE = (64, 64)\n",
    "  image = tf.image.resize(image, SIZE)\n",
    "  image = tf.image.rgb_to_grayscale(image)\n",
    "  image = tf.cast(image, dtype=tf.float32)\n",
    "  image = (image / 127.5) - 1.0\n",
    "  return image\n",
    "  \n",
    "\n",
    "data_flow = data_flow.map(resize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222a887a-e064-4656-8b5c-952863b109f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe7e1b0e2b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAFnCAYAAACLs9MAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0cUlEQVR4nO2dfayfZ3nfv5d9HEJebJ/jN07svDmgZKVAIIYWMSZGmoox1CAkpjJtyiYkg9RJVNsEYZMmVfyTdaKi0qZKEaXNWtYOpWWJUEcbZU0moKKJiWljkuBAstjE9vHbsRNeEju+98f5uTt57s9tXz8f++f7LN+PFB37yvM89+tz+TnP97muK0opMsYY0x8rLnYHjDHGMHbQxhjTKXbQxhjTKXbQxhjTKXbQxhjTKXbQxhjTKUty0BHxgYh4KiKejog7z1enjDHGSHGu30FHxEpJ35d0m6S9kh6R9LFSyvfOX/eMMea1y9QSzn2XpKdLKT+UpIj4Y0m3S2o66BUrVpSpqVc3eerUqeo4skVEyiZJ9I/OOOefK0vtN5H9BzR7TbreihX1L1J0XKsv1DYdu3Llysp28uTJ1HGvvPJKqt1sX2jM47STHQuR7eM4+2Qp18yu9VL28lL3Dt1btAbZtabrjbNPsmTu31OnTunUqVM4kUtx0Jsl7Vn0972SfuFMJ0xNTWnDhg2vsv30pz+tjvvZz36G5w4Z5yajxbzkkksqG20YWkziJz/5SWW79NJLU+222nnppZcqG80FjY+uR07ksssuq2wnTpxIXa/VNp2/evXqynb06NHKdsUVV1S2F198MdXuUvoiSceOHatstCemp6cr28GDBysb7dGsw6B1bjnEVatWVTa6j2jv0f2S/YeTbERr71B/sj5h7dq1lY3W+nWve11lo/sqe29IPGfZf1iGazg/P49tSEtz0LRTqh5GxHZJ26X8YhpjjFmaSLhX0tWL/r5F0vPDg0opd5dStpVSti311wVjjHktsZQn6EckvSkirpf0I0m/KumfnumEUkr1awQ5bfq1IvsOqmX/8Y9/XNno10Ky0a8+9KtU9n1a610l/dp05ZVXVrZDhw6ljqO2qd8EzTe9ZpDyr0iOHz9e2bLvv7PvP2n9qC/0K67Er6ToV+4XXnihsl1++eWV7eWXX04dR3tinHfQtOfpFQCNheaHXj3QcfQahmi9KqD+LOW+pP5k71V6FZLVFSTuI91Hwz1/pgfXc3bQpZSTEfGvJP25pJWSvlRK2XWu1zPGGPNqlvIErVLKn0n6s/PUF2OMMYvwS2FjjOkUO2hjjOmUJb3iGJeIqF7i00t9EnBIQGsJFK9//esrG73Ap/NJFCCBkUQUuh71m4QRiYWeNWvWVDYSmQgS26iP9I0pQQKaxIILzU/2K56s+EOiDoly2W/Jpfy3viT+ZEUi2k8Ezfc43/7TuGlP0P2SFWWz30u3vjunfUJrmL23aG5pn2TH11qrrBidiaE40zF+gjbGmE6xgzbGmE6xgzbGmE6xgzbGmE6ZqEj4yiuvVBFY9GKeRDAS1lqCSVYUosg4ir4ikYGuR+IGiQl0PYkFF7omkRVB6Xpky0b4tc6nyEYSdehcSjo1Oztb2SjJDM3D+vXrK1srQiybpY4EPBJbqT/UxlIiWFttUzuUiIqiIkm8o/uK9klWlGu1Tfv2lltuqWxbt26tbPfee29lo/1E/abxte5VElYpUnapGTP9BG2MMZ1iB22MMZ1iB22MMZ1iB22MMZ1yzjUJz4VVq1aVdevWvcpG4l+2lE0rAocEABJXhtVdJBaeSPAi6NxsSkwpHy1Fc0Fixkc+8pHK9o1vfKOy7d27t7JlK4FI+WhQEgRpDSnqjPbJ1VdfXdkOHz5c2Uhsa0VzZlO+ZgXBrFBLe55EbBL5JJ7vbIGMbORmtlJRtjqMlC8nRufPzMxUNqpq00otm2m3JSbTGGltMgLl/Py8Tpw4gWqin6CNMaZT7KCNMaZT7KCNMaZT7KCNMaZT7KCNMaZTJhrqferUqUo9z6q4dFwrDJoUX1JYSfGnEF4KR6XrkdpPXz7Q9aT8lyoUCk/nkqJNX5rQudkc2BJ/vUDXpOOoHVLdSQ2nsdDXFfSFS+vLHPraJ1twmMacLdxL6zxOEdPsFxbZL0io33Rv0H1JfRkn5DmTQ1nir4/oXLJRf7LHSfniy8RwfzsftDHGLEPsoI0xplPsoI0xplPsoI0xplMmGuo9NTVVhkVQSUQ7duxYZaM8za0X+CQU0flZsYZCbklkonOpDRJRWn3MFkEl0Sqb0zkbJjyOKJsVvbJh4nQ9EswoT29rvonsnNG6kohK/c6mIsiGW0u8/mQjYTybuzs739mCrFI+/D8r6mXzYl922WWp41rh8iRaZ+dnuP6HDh1yqLcxxiw37KCNMaZT7KCNMaZT7KCNMaZTJhpJuGLFiurlPEXVZaMGW5FtVLyRhBk6n84lcevIkSOVLSs8jFNAk0QGaof6TUJPNgKO+t3KB50tMEqRaJMQPLPRqq1rkvhDfSTRKhtdSOPLis4tO+2doUgv8fxkoxhJlKP90BKYaS9nhXWaR8oRTceRAEsRoy1RlvZy9p7JRkpKfoI2xphusYM2xphOsYM2xphOsYM2xphOmahIKNUv3UmMIJGhJVARlI4zW7wzK6JR9NVSIq0kjqDMil5Z4YEEGCrSSrRSXdI1N2/eXNkoio3mh46j9K4kUI2zTwiaW9o7tE+yqTwJug8IEqckLoJL1yTRi6LisgIz3Wu0Z1vFbkmYo31GY6G9ky0QS9HBtFbURutYug+oP9m1lvwEbYwx3WIHbYwxnWIHbYwxnWIHbYwxnTLRdKOrVq0q69evf5UtG3WUjViSWNSj81uCyxASR0hEIRsJTOPUM6OxLCXSkoRIGh+JOq35HicyKnMuzQ/1kYQeEmAoWo3EqVZ/qG0Sj2gNssIhiZsk3k1PT1c2icWo7L1FezQrwJI4SXun5Wey16Q1IDExG11K+4QEz9bepnnMRo0O53t+ft7pRo0xZrlhB22MMZ1iB22MMZ1yVgcdEV+KiLmIeHyRbSYiHoiI3aOf/GLMGGPMOZOJJPx9Sf9Z0n9dZLtT0oOllLsi4s7R3z9z1sampjQUCakO3549eyobCSuUnlPil/3Z6Lus+JetNUdCFgkerXao3zRnlP6Uoh1JtKB2SQRpRVVlRVkSj6gdWj+KLiTxL5vesRUVmU1rSuMjsrX9aE/Q+lFaWYnvDxLCaD/RWLIpWqkN6iONRWKxNivAZgXdrHhP60yCZYtsFPLwuFZksZR4gi6l/G9Jw7v/dkn3jP58j6QPn+06xhhjxuNc30FvKqXsk6TRz43nr0vGGGOkCSRLiojtkrZL7V/tjTHG1JzrE/SBiJiVpNHPudaBpZS7SynbSinbspm9jDHGnPsT9P2S7pB01+jnfZmTTp48qf3797/KduDAgeo4emlO4k1LtKJINLrmtddeW9lI4CABLisSUjRXK90gCRLZKC+aC4pEo7ZJgKHoKxI8JR439ZvmjMaSrZtHfczWmqPjJJ7HbLQtjY+uR+tMDy9ZIatlp6hRElbJdvTo0cpGeycr1LX6TTUEaX6y9xYJsJROl/Yd3futaGO6Z6iPrYjVxZwpEjfzmd0fSforSTdGxN6I+LgWHPNtEbFb0m2jvxtjjDmPnPUJupTyscb/uvU898UYY8wiHElojDGdYgdtjDGdMtGahKWU6oU4vVgnG0UDtcQ2EsdIuKDjSHii/pBolY2+aqUbzaaCJCGEhJ65ufrjmqwoQwJMq64ciSskfNBYyEYRotQGzSNFrFFfWmPJRtplBSpaFxLM6Hrj1FykeczWV6T7gMRNGh+dS6JcK1UtrSHdMzRn2XSj5DtI/MtG8krse7JpaYdzcaY6mn6CNsaYTrGDNsaYTrGDNsaYTrGDNsaYTploTcKVK1cWSiU5hF7+03mtlJEkUszPz1c2eqlPYka2BiAdRyJKSzDJCkUkotC5JP6RaEVCDQlrrYgnEkIo6rAV+TkkmzKU5jsbRTqOaJUV9ajftFa0J0i8oz3Wgs4nISybtjWbopXGR2JbKw9Pdp/QfGfT5GajZ6mPrTWga2b3yXBuDx065JqExhiz3LCDNsaYTrGDNsaYTrGDNsaYTrGDNsaYTploqPeKFSsq9TOTL1VihbQV6p3N/7uUMNOsUp394qJ1fvarBOoPqeH0VQi1Qee25pvmJ/tlQDaUnc6luc3OzTjVfbJ7J5uzmr72aOUdHkLzKvH8UNvUTvZrGDqX1p6+omoVu6XQfNp7NL5MQVYpfw9mC9O2zqd9Rn0c7qclFY01xhhzcbCDNsaYTrGDNsaYTrGDNsaYTpl4Pujhi3R62U4v+ukFPNlOtzOEXvZnw3WzYc8krFDeYQrBlvKFKLNFdbNCFok/2RBlicVDEvpofJs2bapsBw8erGwkHGULspKw1srBmy38SetK+4kExta+zZzb2jtLKURLNpqHLVu2VLZhEWiJBcGWKEt7lOaHBE9aFxIo6VyC1rR1biun+xAay3Buz5Ruw0/QxhjTKXbQxhjTKXbQxhjTKXbQxhjTKRPNB33JJZeUDRs2vMqWzTtL/SQRpHV+NlqOIu1I4KD+kLCSzecscc5ruiYVg12zZk3q3GwhURJHWrlxsyIjiTo05uzcZqMLiVaEGK012ag/dBwVwKX5pv5kc4637JRrORutmo3my+bAbpHNyzzOfhxCfSQfQWJ3a5/QsdTHjAB7+PBh54M2xpjlhh20McZ0ih20McZ0ih20McZ0ykQjCSOieml+/fXXV8c9/fTTlY0EppbASaIViXUU+UXtZFOQUhQTiRGtqCoSlCi6ae3atZUtKwiSkNGKEBwyjvhD0LhJyCLBk0Qrilg7evRoZVu3bl1la6VOpTmjSMRWythMO9mUqDQ3rQi2bCpXapvmm/Y33RvZtJstsS27/tRvslH6UtontJezKValfGQzzc/wHnQkoTHGLEPsoI0xplPsoI0xplPsoI0xplMmKhJKtXDxgx/8oDomWzePotAkjjDK1lMjYYUEKhLWKOUjiUR0PYmFFLomjZv6Q2Omtkn8IQGm1e+lRKeRaEnrQmOZn5+vbNnIRNpjEgtUrTqAQ7IRlevXr69sWcGTRDWJ90lLmMucS+L0Uup6tqL+qB0Sy2kNaF3pPsimFc5GMEs8RtpTWaG2hZ+gjTGmU+ygjTGmU+ygjTGmU+ygjTGmUyaabnTlypVlKBSRqEOCQlYYk1j0ICGLXvRno6BItKCX/3QuCUJSPmUoiRnUdnZt6VyaLxI8JJ4zEh5JRKPxZWvkZdNfjjM3tM9I3KTjSIzKRkXSmI8dO1bZSBiV8oIi7Z1sPUsim563VQMyGyFMe4yOo/uS7nMSp0mwbImy2XmkqN/h3M7Nzenll192ulFjjFlO2EEbY0yn2EEbY0ynnNVBR8TVEfGXEfFEROyKiE+N7DMR8UBE7B79nL7w3TXGmNcOZxUJI2JW0mwp5TsRcaWkHZI+LOlfSDpSSrkrIu6UNF1K+cyZrrVq1aoyMzPzKhsJPfQCnwSmlkiYjSbLpmgkshFUdL3WnJPIQHORTfHYEmYy51IbLXGTjiWxJiuskMibFdZIEKT+tdKF0jUpGpRSy9K6UtQgiWjZ1LCtNSCxjWx0TYJERxofXY/2UytVbTZyN5vek6IQyXfQfFMfac9Keb9FwuPw3ti7d69eeumlcxMJSyn7SinfGf35BUlPSNos6XZJ94wOu0cLTtsYY8x5Yqx30BFxnaS3S/q2pE2llH3SghOXtPG8984YY17DpJMlRcQVkv5E0q+XUo5nE35ExHZJ26X8r9zGGGOST9ARsUoLzvnLpZQ/HZkPjN5Pn35PPUfnllLuLqVsK6Vss4M2xpg8Z32CjoVH5d+V9EQp5bcW/a/7Jd0h6a7Rz/syDWacdDY9YKteGIk6JOqRQEFRjNkIQWqDaqS10kBS2yRcUH9IzMieS8fRfLfSbpJ4RHNB46YxD4XkFnRuNgKyJVqRwJw9v1Vrcgj1myLyWgIVQeu1lNSrFAFHAuX0dP3xFomTrfSuNI9HjhypbCTAUZQmQXOTFR1b0Nxmox2HIviZPtTIvOJ4j6R/LulvI2LnyPbvtOCYvxIRH5f0nKSPJq5ljDEmyVkddCnlG5JaL5xvPb/dMcYYcxq/FDbGmE6xgzbGmE6ZeE3CofBBggKJfNloN2qjdX629h0JHCRQ0HEkbrSiFWnc2UhCEv+ydeqo3WwayVbbNEY6PyuEZaMQ6TiK5qIxSxzFRoIZQWOm9cvW3KRUl61+E1khk0RLitKl61FK1Kw4LfEa0hhJlCPfQeOj+c7WOGxB85NNiTtOu36CNsaYTrGDNsaYTrGDNsaYTrGDNsaYTrGDNsaYTpn4VxxDhbcVcjuEFNKW+plVybN5lbNfOdBx44TrUh9p3NQ2HZedM1K+s3MjLS2v9jj5sofQ3qGvcGhdWuHklOeZvuygMVO/6esFWj/6KoC+rmjtJxo3rRf1h/YJffnSCtceQvPQSvFw+PDhVNs07mwuaRoz3WvU79ZezBaczu6JFn6CNsaYTrGDNsaYTrGDNsaYTrGDNsaYTpmoSHjq1KlKDKEwWgqPzeYxllhcyeb5zRbBJBEtW5CzJfTQNbPh6AQdR0U1SZQhEYwKiUosMtLakC1bzLcV1j+E9hPZSEySeJ9lRS/aJyRG0fqTjeaBciVLLIRSLnIaC90v2T2WFXlbAjPdl7Q2FPZOa0B7kULCaS/SfLf6nS1OTOkWxsFP0MYY0yl20MYY0yl20MYY0yl20MYY0ykTFQlXrlxZCRcUnZR9gd/KtUq5XumlPokHJKxkxT+CBI9WdBL1MSs80XEk9JCoQ9cj0alVpDMb+ZeNdssKKyTKzM7OVrYNGzakrteCBDzatyRkUYQgCbW0F2k/tMQ76k92T5DYtpR8x9mixlI+8i8bkUv9oehQEsZp3x08eBDbIWGVfAcdN7xfnA/aGGOWIXbQxhjTKXbQxhjTKXbQxhjTKRMVCUsplSCVTUtJIkErbd/09HRlI9GDBIqtW7dWNhJwnnvuucpG4iTREh2zYhuJPyR6kPhHaTapPyR4kdjSaods2TSLFF1G4s+mTZsq27XXXlvZaMytfUdrTSkxSZQjG12P9iKJslSQtTWHND/Z9LW0/nRv0D1I52Yj/CT+ICC7n2gNsyla3/jGN1a2J598srKNEwFJ6z9OClPCT9DGGNMpdtDGGNMpdtDGGNMpdtDGGNMpExUJI6KKZCIxigQTEgRaggmJK9l0lVdddVVlowij/fv3V7ZsPcMWJIQQ2Rp5NGcUSUZCzTi1Aqk/FFVF6UpJPCIRbf369ak2SKCiNWitC42bhD5K+5lNnUo2EiKpL8ePH69sEgvU2QhBErxIWKN9QmswjqBP0HyTCJ6NTCV27txZ2Wh8rdqVNI8kEpLfGe49iiw9jZ+gjTGmU+ygjTGmU+ygjTGmU+ygjTGmUyYeSTiMPCKBiaKBSARppaWkF/N0TRKoDh06VNmyNelI5KO+0LkSC1fZ9JA0FxRRSedma8C1oD7S+SR6UX+ohiDNDa0LCT1ZAU3K10OktimqjmwkJpGIRvuplW6UxDESsuh8EtVpzrJpgGm+WgJ4tm4iQUJtVtxcSkpTidcw+0HAsN9natdP0MYY0yl20MYY0yl20MYY0yl20MYY0ykXPd0oCQL0Ap9EJ4ouk1j0IHGEBI7vf//7lY3EtmzUIImTLUi4yooZJKxRLT6aBxJ1SNyan5+vbK0+ZkU0WtdsbUYSsmhP3HDDDZWtFVm6Z8+eykbRe7R3SKilqLgs2dqTEs8F7UcShGldaA3ouKwg30rFS3uZrpmN0qN9R8fRBwK0fq35zorWmbqg9GHCafwEbYwxnWIHbYwxnWIHbYwxnXJWBx0Rl0bEX0fEdyNiV0T8xsg+ExEPRMTu0c/6Ra0xxphzJiMSviTp/aWUFyNilaRvRMT/lPQRSQ+WUu6KiDsl3SnpM2e72FBcoSgfejFPEUctAY5EAUrpt2bNmspGYgRFLBHZ1JKteniUUvGaa66pbBQhRnNGIuEtt9xS2d785jdXNhLvHn744comcS03ErhIMKO1IiGLRNB169ZVti1btlQ2qjPZikIl+4EDByobzTftnWytQNrLlAa0Vc+S+kNCGAmeJE6TIExCH405G/0q8V4mn0Dn097JRjvSfI0TuUkiKt3X1PY4nPUJuixw+m5dNfqvSLpd0j0j+z2SPryknhhjjHkVqXfQEbEyInZKmpP0QCnl25I2lVL2SdLo58YL1ktjjHkNknLQpZRXSik3S9oi6V0R8fPZBiJie0Q8GhGPLvVx3xhjXkuM9RVHKWVe0kOSPiDpQETMStLo51zjnLtLKdtKKdta76GMMcbUnFUkjIgNkk6UUuYj4vWSfknSf5R0v6Q7JN01+nlf4lrVi31y2hSRQ2ICiSCn2xlCAhyJAvSUT+1QBBQJDyR4tdISUr8/+clPVrbHHnussj300EOVjeaRBLP3vve9qXNJqJNYUHzmmWcqG407GymZFcFWr15d2ajfrd/mSIxuRcENIZEom3aV5mac2n4k1mWjdOk+oPslK4xRv1uCPrVDY8mSFQmzqW9bkYR0PvmobM3GFpmvOGYl3RMRK7XwxP2VUsrXIuKvJH0lIj4u6TlJH023aowx5qyc1UGXUv5G0tvBfljSrReiU8YYYxxJaIwx3WIHbYwxnTLRdKOnTp2qIqGyQgYJQq2IPHoJT0IICXjUH0oHSBFrFOVFAkUrBSWN5/Of/3zqmsTBgwcr2ze/+c3KRhGHFMFI0ZgSC1xZUY8EIRJ6aE3HEXUybUj5tLQERSGSwEhjoXmg+WoJzNn0rjS+bFRddk2zUZYS34O0Ntm0vVmBme61rBgs8XjoPsr6ohZ+gjbGmE6xgzbGmE6xgzbGmE6xgzbGmE6xgzbGmE6Z6FccU1NTmpmZeZWNvpAgFZfUZwqjlfKh2aTEkrpLeXmzxUDpei0Vl/Lb7t+/P3Ucqfg05p07d1a2H/3oR5WNQnBb801fi9AXH9Qf+kKCvs6gPUFrQH0hWysfNOVLpvPpqwLqI31Jkc3zTPPVSm+QLYKa3Y80Ftp3dC71ZXjfn4bG2NpnGchP0JoSNOZx0kmQP6F9Mhwz3bun8RO0McZ0ih20McZ0ih20McZ0ih20McZ0ysRDvYcv0inUsxXCPYTOlVhwaR07hEQGEqPoxX42hLN1XCv8eEi28EFLCBtCeWzHgUSdbLFUGjP1h9aFRBkqdrp3795U/yRp9+7dle3w4cOVjeaWQoopfJiEI8obTEJrKx90tm3ay3RvZHMok43ExNZepH4vJW94Vlil8dFebAl41A7NN41lOBetFAqSn6CNMaZb7KCNMaZT7KCNMaZT7KCNMaZTJioSrlixohIQjh49Wh1HIgPZWmJZNk8wCQUUNUaFSEm0oOuRyEBRehL3OxOJJLEARyJaNl8y0RJMqG3qN61htjAqiS0kBpMYdeDAgcrWyk9MUZUkEtL4sn0kqN8k3o1TxPTYsWOVjfpI+5ZsNJZsJGGr39QORVrS3qN2qD90Lt1rNL7WBwvZPPa0v4f3QUv4lfwEbYwx3WIHbYwxnWIHbYwxnWIHbYwxnTJRkbCUUokC9KKfbBRtQ9FXEgsS9CKebCRkkaBEQgb1O5uCUmLBJCvqUNskhNBY6HpZQU/KR1CSsEYRgiSiZtsgsY2iC1viTzbtZzZNJolJ1DatAe3j1p6ncWcLxC4l+o7GQmNuCczUR7rm9PR0ZZudna1sNA8USUp7IhtRKeUjYLMFsFv4CdoYYzrFDtoYYzrFDtoYYzrFDtoYYzploiKhVL80bwlPQ+jFeqvWWFa4IIGC+kPCEYkE2Vp6Z4ocyvSHIFEvm1Ix20brOFobWoNsylASEymVIwmHFPVHc9NKP0v9IeGJBCGab5ozEupovrZs2VLZSCyTpOeff76y7du3r7LR3FLbWcErG/VH7Uo8P9Sfm266qbJ97nOfq2w7duyobF/4whcqW3b9WuJmNp0u7b2hP3FNQmOMWYbYQRtjTKfYQRtjTKfYQRtjTKdMPJJwKMKQYJKtzddK25mN/KKX+iR6ZFOLLiUFqcTCBQlwlP6UhMxsJBrNDYk6rfSuNI8krGXnLJtaNltfj1La0rlSfu9koyKzEWe0pm9961sr23PPPVfZJE6TSvOYraVJQh2tFe27bPrSVn+obVpXulfpuKUI/y1Bn+y0RzNRlRYJjTFmGWIHbYwxnWIHbYwxnWIHbYwxnRJnekF9vpmamipDMYSEDBItKO0mpXeU8mk/s3XgSGTIpgFtpbUksqlJac1IEGxFyw2hsZCQ1RpLVjChsZDQSzbaJySskXBE0Xct8YciEY8cOVLZDh06VNmoniVBc0NjWbt2bWWjtLtSPvKP9g6JqCR40n6ie4jaaKVJpchNun+vu+66ynbjjTdWNpqfXbt2VTaKQqZo1VbtymzUKI1leM0jR47oxIkTuCH9BG2MMZ1iB22MMZ1iB22MMZ2SdtARsTIiHouIr43+PhMRD0TE7tFPTrNljDHmnEiLhBHxryVtk7S6lPKhiPhNSUdKKXdFxJ2SpkspnznTNS655JKycePGV9myEWskEpG4JbGoQy/rs3UKSYBZs2ZNZSOBgoS1Vk0yajtbi49EHeo3iTo0FjqOBDipHWE4JBvZmI1Eo71LQhaJbS3xh4Rn2qNkI5GI+pgVmGkNWkJttiYh7THatySY0Tpn16XVb9qjMzMzlY0EdOojrQv1kY4jH0P9a51PY6Q9Pzz3xRdf1MmTJ89dJIyILZL+saQvLjLfLume0Z/vkfThzLWMMcbkyL7i+IKkT0ta/E/RplLKPkka/dwI5xljjDlHzuqgI+JDkuZKKXWpggQRsT0iHo2IR1sJU4wxxtRkoijeI+lXIuKDki6VtDoi/lDSgYiYLaXsi4hZSXN0cinlbkl3SwvvoM9Tv40x5v97xookjIj3Sfq3I5HwP0k6vEgknCmlfPpM569ataoMBRsSayiSjESCVlpSihLKprWkF/3URxKE6HoECQdSXhwlQYiOIzGSovmytMTAbHpIguaW1pXmjESirNDaiiSkdsiWFQQJmkdqIxt52Wqb+ki/xZJISMIq9YfaoLml60m8NjQXrQ8ChmRFQto7dFxrz5N4mI3IHd4bc3Nzevnll897JOFdkm6LiN2Sbhv93RhjzHlirIT9pZSHJD00+vNhSbee/y4ZY4yRHElojDHdYgdtjDGdYgdtjDGdMtGisRFRfVlA6nNWISUFWeKvF6idbC5a+mqCjmv1J9MXiUNzSUWmuaAwbCqMSuo1qfOkrrcU7WwoNIWU05ipP/SlCI2vFUY/ZMuWLWinNaR80jt21GEB2XzCNLc0D9mvh1pkv0hZt25dqh36uiYb8kzHSXwvZFMHZL8gyRbApblpfZlF/ab5oXUd9qf1RZHkJ2hjjOkWO2hjjOkUO2hjjOkUO2hjjOmUiRaNpVDvbAHUcUQ5EhnoZX02PJZe/mdFRwrNbeWYpT4S2SK2JKIR2eKkrb1CIgytQTZPcHYNWiHzQzZv3lzZ3vnOd+KxDz/8cGWj9aK1JjGZBEYq0krzQKHHZxKUhmTnLHsfUB+pDdqLrbXKFhymdug4yudN+ztb1LjVb1qbbB+H9+X8/LyLxhpjzHLDDtoYYzrFDtoYYzrFDtoYYzplopGEUi00ZEVKellPoozEIkU27yzlMSZxhISjbBRiK1cynU9iBPVnfn6+spEAk40GIxGMIuVa52cLulI7NGaK6KL1I1GGIhgfeeSRyiblhdWsEE1zky3mSue28iKTwJUV22iPrl69urJlKyJlC+pKPB7aE7T+NBYqOEtjoXuIBEaytchGfg7X35GExhizDLGDNsaYTrGDNsaYTrGDNsaYTpm4SDiEXvRn0022ClGSOJJN09gSHoeQCEYi3ziRXyQyZIpOSpxuNJuOkWwkCLbSQGZTnRLZaLmsWEp7Z8+ePen+0RhpT9Bx1MdsOs2ssNZag0xay3HaJnEsG+1Igl5L3MzOD51P/bnmmmsq20033VTZKMXqM888U9l27dpV2SSOtKV90vJRizlTelU/QRtjTKfYQRtjTKfYQRtjTKfYQRtjTKdMVCQ8depUJc6Q4EWCAIkJrSjEbGQbCXBXXnllZaM+kiBA4haJVi3BhCLjSPyhqEiChL5sVGS2bp7EYhbNd1agJEhIOXLkSGXbsGFDZRsnGozEw1ZduiHZSFCCxkfia2vP0xpka3uSUE/7hKA2aMyUdlfKpzWlCEG6t66//vrK9olPfKKy3XjjjZXtD/7gDyobCcySdPjw4cqWrSs5jGx0JKExxixD7KCNMaZT7KCNMaZT7KCNMaZTJioSrlixohKuSNAjUWYckTCbwpQEQRJrKGqIRAuqNUfCQStakcQaIpuikURHEsxIpKA2WmJGNsKMbDQ/JNRRf0gEpfHRfjp27Fhlk1jMIjEqO2c0Ftp3GzdurGwHDx6sbC3xLlvHkY4jQZjOJVtWyGzt+aWkkaX5JhtF85GgS2lJ6TiJ14HuQZqzcaKL/QRtjDGdYgdtjDGdYgdtjDGdYgdtjDGdMvF0oxkBj17Mk5jYgkSY48ePV7ZsDTkSUagG4FIjILPpJbMpSEmMoONIHKHxtVK20nplhadsukq6HomE2VqRNOZWf7KRceNEXw6h/UnXG0dgykYN0pzR3JJYnk0D24rmJAGP7sH9+/dXNtonlDL0y1/+cmXbvHlzZduxY0dlm5ubq2wtshG+Q4GaRNHT+AnaGGM6xQ7aGGM6xQ7aGGM6xQ7aGGM6ZeLpRoeCBAkCJPKRQEVRTBILEtROth4eiUwkUGRFvla6URIZsudnxRoSf2jMtAYUKdlqmyBxlM7NziOtabamYCtqk6IGSVil42h82Ui5rFjaimyjOaM+rl+/PtV2Np1uNlUptds6n8adFW/37t1b2b71rW9h20MOHTpU2VrCH611NkpzOI9nun/8BG2MMZ1iB22MMZ1iB22MMZ2SegcdEc9KekHSK5JOllK2RcSMpP8u6TpJz0r6J6UUfklpjDFmbCIT2Tdy0NtKKYcW2X5T0pFSyl0Rcaek6VLKZ850nVWrVhVK0zmERBQSLVpRWtl0oySiZOvKkXBEIgEJehQ1Jklr1qxJXZPmh8Q/EswoQpDGR5FWrRSdlGaR1ob6TYISCSvZKK2seNPaO1lRlo6jPlJ/smlJqY1WulGaW7om7RMiO4+0d+jcq666Ctuh/ZgVCbOiJUV9ZutUtqL8aIx0LPVxKG7Pz8/rxIkTGCK6lFcct0u6Z/TneyR9eAnXMsYYMyDroIukv4iIHRGxfWTbVErZJ0mjn3XGcWOMMedM9jvo95RSno+IjZIeiIgnsw2MHPp2iX9lM8YYw6Q8Zinl+dHPOUlflfQuSQciYlaSRj8x7VMp5e5SyrZSyjY7aGOMyXNWjxkRl0fElaf/LOmXJT0u6X5Jd4wOu0PSfReqk8YY81ok84pjk6SvjtTIKUn/rZTy9Yh4RNJXIuLjkp6T9NGzXaiUUind2S8k6CsO+npA4i8x6Omd1OJsMVBStKld6iO1K505L+xiqI/0RQrNGYVwj1NUNdufpXypkN0TNN/UBqUEaOW2zn4tQl8fUG5jWgP6AoC+PsiGhLfs9MVHNj95tpgz5ZKmr5HoOIlzTNNXF9kvhWgs9MUGnUtfuLT2CX2JRfND9+WwnTPda2d10KWUH0p6G9gPS7r1bOcbY4w5N/xS2BhjOsUO2hhjOsUO2hhjOmXiRWOHYga9rCfhKBvWKbGgRCJFtsgrtZ0NJ8+G+kosKGTFTWqHxBoSJLL5t8fJoUxiG12T+k2iHolEWQEum2tZ4mKyJNbRGmZzmxPUHxpfS0gmQTBbNJjWhc6lecwKo61PbLPzQ8dlQ6uJbH74loBH9wLtCerPUMh2PmhjjFmG2EEbY0yn2EEbY0yn2EEbY0ynTFQkLKVUL8SzkXb0sr2V05eiyYhsoU0SVqjfJBJQH8cpRJmNlsrmp80Wux0n+o4isChCLJvfmMZC60KCXnZdWmISRQhmhVoSjrKFgEm0ovVrCbVZUS+b05mgc6enpysb3S+tgsO0/lkxOSsc0j1E8z1OznmKYh3n/MXQvXIaP0EbY0yn2EEbY0yn2EEbY0yn2EEbY0ynTFQkXLFiRfXSnAQcEoTouJbYlhVm6AU+iTAUTZQV7zZs2FDZ5uawtgEKc9k0oiRakRBCogyJRNTuOJGb1E42RSeJfzRmSiOZjSRsjYXstNYk7NBxFMGaFcFpDmkeJL4/svcMjZnaJgGORFnaO61it9RHEv9o3NmCtSRQLmUNWseSj6EPFobz7UhCY4xZhthBG2NMp9hBG2NMp9hBG2NMp1z0SEISLbJiBIlqEke2kXBBL+ezUVVZgZGELIpCklh4IjGDzifRgmw0NySs0HzTuVI+KisbfUVko+pIdCSRqBVtSutKkW0kbpGYTCIx7cWs6EgCqpSvK0jQPNL1qO1sitzWvUoiaitidQjdW7T+dA/R/iZBsCUSkt+iPZGNGm3hJ2hjjOkUO2hjjOkUO2hjjOkUO2hjjOmUidckHIoP9MI8m3qxJehl02xmo4nIlo1syoooLUhEIUiEISGDovlIlLniiisqWystYjaqioSnbLpJilakdaY+0lhakYQEiVEk4JEIevz48cpG+47mIVtbs3VNstE1aa2yUZpE9p6WWHim/tC4aV1p72TrkY5T45DGk61dOtwnZ6qj6CdoY4zpFDtoY4zpFDtoY4zpFDtoY4zplImKhBFRvSCniC4SW0g4aIltJNaRqJNNqUliG4kt2RpwrX5TOxS9RQIF9ZuEEBJMKL1jVhBqtU1iHbVDEV3ZqFEaCx2XreEosVBEAh6tIc1Ddv2z4lZL3KQ9ce2111Y2ug8oApLuQVoX6jeJXnS/SLwOJMDTumSj+ciWFZNb4uY4IvOQce4tP0EbY0yn2EEbY0yn2EEbY0yn2EEbY0ynTDyScMhSovlaqQBJUKAX8yQykDBDggmdSwIMCR7j1DmjY0m4yIotMzMzlY2ixqgvrTSp2fSnNLfZiDyabxIESbTKplOVWFCiPUqCEtWazNYppLHQ2rfqcJJoRf2h8WXrCtJ9RYInieWtKFQ6lvYOrUH2wwHaE9PT05XtyJEjqeNafaR5pL1M89jCT9DGGNMpdtDGGNMpdtDGGNMpdtDGGNMpE69JOBQfsvXQ6KU8iVsSpzDM1pXLiigkWpB4RxFUrZprFGlHkZZ0TRKtCBIO6dxsDcDWNSkCMit6ZaMBaW7Wr19f2UjwaoltJKJSpF026iybqjQrbrZqKVItPjo/G+GZFaKztStbAjOJhNl0rIcPH65sJBJmU9XSmrb2STbamcY3nMczRRb6CdoYYzrFDtoYYzrFDtoYYzol5aAjYm1E3BsRT0bEExHx7oiYiYgHImL36Cd/0W2MMeacyD5B/7akr5dSbpL0NklPSLpT0oOllDdJenD0d2OMMeeJOFtu0ohYLem7kraWRQdHxFOS3ldK2RcRs5IeKqXceKZrTU1NlaFSSiopqcBEK1w3+zVEttBq9qsSUnGpj2vWrKlsEqvSdCxdM6vEk/qczenbWhf6iiNbLHfjxo2VbcOGDZXtqaeeqmwUMv2GN7yhsh09erSytdbghhtuqGy7d++ubNnw6Oz+pq8UaM+2coln8zxnv5rIfs1E1yNb6wugbFqHbKFlWoNsgViaw1Zh6qWkFBiu//z8vE6cOIGVYzOj3irpoKTfi4jHIuKLEXG5pE2llH2jju2TVN9pxhhjzpmMg56S9A5Jv1NKebukH2uM1xkRsT0iHo2IR1v/GhljjKnJOOi9kvaWUr49+vu9WnDYB0avNjT6WafOklRKubuUsq2Usi37a4oxxpiEgy6l7Je0JyJOv1++VdL3JN0v6Y6R7Q5J912QHhpjzGuUs4qEkhQRN0v6oqRLJP1Q0r/UgnP/iqRrJD0n6aOllDqh6iKmpqbKMAQ4KyhQP1uiFYlCdE0SZkgwIRGMhAcSKAg6V8oXwaS5INEjW8Q2m3+3Fa6bDUnOXpOOy+YnpnUmW6uIKc33W97ylsq2a9euyvbss8+m2iay90ErTQDNGa0LXZPmMZvjm34rprUiAU5ioZf6nc0bny3SS2HdBw4cqGyzs7OVTWLxL1vYdrgGR48ebYqEqVwcpZSdkrbB/7o1c74xxpjx8UthY4zpFDtoY4zpFDtoY4zplJRIeL6Ympoqw7y19FI/KxK2Ptuj87MRTyQ8ENQfut44nxaSkEJiG80ZiSjZiEpql0SQltDTypk7JLsGWTGRxFsSnSjHMx3Xaof2E42Z5nbdunWVjeaWBOvjx49XtpbATHuCckRnxS2KQqU+ZsXN1t7JCmtZwTMbNUhC5jii7FLu/6GPeeGFF3Ty5MlzjiQ0xhhzEbCDNsaYTrGDNsaYTrGDNsaYTplo0diIqF6aZ9MsksjQEqdIFCDxLyv+ZM+ldgkSwSQWhbJRfhRVmYlikrjf2QKYEhdG3bp1a2U7ePBgqh3qNxU7XUpkWyvqMytGkW16uq5ZQWIb9TtbfLUl6mcL8tJakxBGRX/pXBJqaX+2xDZaLxJqs+lrCbpeNsq2VYw5Oxe0Llk/IfkJ2hhjusUO2hhjOsUO2hhjOsUO2hhjOmWikYQRcVDS/5G0XtKhiTV8YfFY+sRj6ROPpebaUkpdiFMTdtB/12jEo6UUSl+67PBY+sRj6ROPZTz8isMYYzrFDtoYYzrlYjnouy9SuxcCj6VPPJY+8VjG4KK8gzbGGHN2/IrDGGM6ZeIOOiI+EBFPRcTTEXHnpNtfChHxpYiYi4jHF9lmIuKBiNg9+lknZOiQiLg6Iv4yIp6IiF0R8amRfdmNJyIujYi/jojvjsbyGyP7shuLJEXEyoh4LCK+Nvr7shyHJEXEsxHxtxGxMyIeHdmW5XgiYm1E3BsRT47um3df6LFM1EFHxEpJ/0XSP5L0c5I+FhE/N8k+LJHfl/SBge1OSQ+WUt4k6cHR35cDJyX9m1LK35P0i5J+bbQWy3E8L0l6fynlbZJulvSBiPhFLc+xSNKnJD2x6O/LdRyn+YellJsXfZK2XMfz25K+Xkq5SdLbtLBGF3YspZSJ/Sfp3ZL+fNHfPyvps5Psw3kYw3WSHl/096ckzY7+PCvpqYvdx3Mc132Sblvu45F0maTvSPqF5TgWSVtGN/r7JX1tZFt241g0nmclrR/Ylt14JK2W9IxGut2kxjLpVxybJe1Z9Pe9I9tyZlMpZZ8kjX5uvMj9GZuIuE7S2yV9W8t0PKPXAjslzUl6oJSyXMfyBUmflrQ4H+ZyHMdpiqS/iIgdEbF9ZFuO49kq6aCk3xu9fvpiRFyuCzyWSTtoKozoz0guIhFxhaQ/kfTrpZQ6IfUyoZTySinlZi08gb4rIn7+IndpbCLiQ5LmSik7LnZfziPvKaW8QwuvNX8tIv7Bxe7QOTIl6R2SfqeU8nZJP9YEXs1M2kHvlXT1or9vkfT8hPtwvjkQEbOSNPo5d5H7kyYiVmnBOX+5lPKnI/OyHY8klVLmJT2kBa1guY3lPZJ+JSKelfTHkt4fEX+o5TeOv6OU8vzo55ykr0p6l5bnePZK2jv6zUyS7tWCw76gY5m0g35E0psi4vqIuETSr0q6f8J9ON/cL+mO0Z/v0MK73O6JhbIevyvpiVLKby36X8tuPBGxISLWjv78ekm/JOlJLbOxlFI+W0rZUkq5Tgv3xv8qpfwzLbNxnCYiLo+IK0//WdIvS3pcy3A8pZT9kvZExI0j062SvqcLPZaL8LL9g5K+L+kHkv79xX75P2bf/0jSPkkntPAv6sclrdOCqLN79HPmYvczOZa/r4XXS38jaefovw8ux/FIequkx0ZjeVzSfxjZl91YFo3pffp/IuGyHIcW3tt+d/TfrtP3+zIez82SHh3ts/8hafpCj8WRhMYY0ymOJDTGmE6xgzbGmE6xgzbGmE6xgzbGmE6xgzbGmE6xgzbGmE6xgzbGmE6xgzbGmE75v4ln85iOE4GhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterator = iter(data_flow)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(next(iterator).numpy().astype(np.float32), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87ba83de-7377-4fe5-9332-a04ae5aedb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disturbed Galaxies: 1873\n",
      "Merging Galaxies: 1423\n",
      "Round Smooth Galaxies: 2628\n",
      "In-between Round Smooth Galaxies: 1829\n",
      "Cigar Shaped Smooth Galaxies: 2043\n",
      "Barred Spiral Galaxies: 334\n",
      "Unbarred Tight Spiral Galaxies: 2027\n",
      "Unbarred Loose Spiral Galaxies: 2645\n",
      "Edge-on Galaxies without Bulge: 1853\n",
      "Edge-on Galaxies with Bulge: 1081\n"
     ]
    }
   ],
   "source": [
    "for name, count in zip(labels_names, np.unique(labels[:,:], axis=0, return_counts=True)[1]):\n",
    "    print(f\"{name}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c192cee3-cfff-43a3-a5f2-a4939e4e82b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_TensorSliceDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(labels[index])\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m----> 9\u001b[0m \u001b[43mshow_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mshow_image\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_image\u001b[39m(index):\n\u001b[1;32m      2\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint16), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(labels_names[np\u001b[38;5;241m.\u001b[39mwhere(labels[index] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(labels[index])\n",
      "\u001b[0;31mTypeError\u001b[0m: '_TensorSliceDataset' object is not subscriptable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(index):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(images[index].astype(np.int16), cmap=\"gray\")\n",
    "    plt.title(labels_names[np.where(labels[index] == 1)[0][0]])\n",
    "    print(labels[index])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_image(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfd40e6f-6186-410b-9596-2df796410470",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "images = scaler.fit_transform(images.reshape(-1, 64*64))\n",
    "images = images * 2 - 1\n",
    "images = images.reshape(-1, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "683aa63a-5d15-422f-8786-2558b7c7b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 17736\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Batch and shuffle the data\n",
    "data_flow = data_flow.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1fafa7-e30e-40e0-b011-107d16865fd8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78381a83-f8ab-49bc-b626-1f5114e49377",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "codings_size = 100\n",
    "\n",
    "generator = Sequential([\n",
    "    Dense(4 * 4 * 512, input_shape=[codings_size,]),\n",
    "    Reshape([4, 4, 512]),\n",
    "    BatchNormalization(),\n",
    "    Conv2DTranspose(filters=512, kernel_size=4, strides=2, padding=\"same\", activation=LeakyReLU(0.2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2DTranspose(filters=256, kernel_size=4, strides=2, padding=\"same\", activation=LeakyReLU(0.2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2DTranspose(filters=128, kernel_size=4, strides=2, padding=\"same\", activation=LeakyReLU(0.2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2DTranspose(filters=1, kernel_size=4, strides=2, padding=\"same\", activation=\"tanh\"),\n",
    "])\n",
    "\n",
    "discriminator = Sequential([\n",
    "    Conv2D(filters=64, kernel_size=4, strides=2, padding=\"same\", activation=LeakyReLU(0.2), input_shape=[64, 64, 1]),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=128, kernel_size=4, strides=2, padding=\"same\", activation=LeakyReLU(0.2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=4, strides=2, padding=\"same\", activation=LeakyReLU(0.2)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=512, kernel_size=4, strides=2, padding=\"same\", activation=LeakyReLU(0.2)),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41b589de-5ea4-481c-833f-581c5d8010b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8192)              827392    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 4, 4, 512)        2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 512)        4194816   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 8, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 256)      2097408   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 128)      524416    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 1)        2049      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,651,713\n",
      "Trainable params: 7,648,897\n",
      "Non-trainable params: 2,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efa3e01c-a173-4cc7-ba23-0f294ecaf2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1088      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 256)         524544    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 512)         2097664   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,766,529\n",
      "Trainable params: 2,764,609\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5eeed0-ab02-4477-9d88-b8dac2045e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.002, beta_1=0.5, beta_2=0.999)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.002, beta_1=0.5, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8b92e88-881e-4fa3-af89-28effa3b4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40bd0f4f-3a0a-4cc0-a3b9-ac1615fd1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, codings_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8492b4f9-71bd-4e00-9ca6-33add0f9b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, codings_size])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2566e002-c17d-48fc-96ea-9c2642f0c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_images(generator, epoch + 1, seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_images(generator,epochs,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af4e41db-cb79-43c0-9582-21434f00bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff731be-3502-4cb8-84af-7e61bd43d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time.sleep(5)\n",
    "train(images, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773f937c-b0dd-4441-b9a2-598da75d9425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        images: 13.0 GiB\n",
      "                        labels: 173.3 KiB\n",
      "                           _i7:  1.3 KiB\n",
      "                         Model:  1.0 KiB\n",
      "                     MaxPool2D:  1.0 KiB\n",
      "                       Dropout:  1.0 KiB\n",
      "                          Adam:  1.0 KiB\n",
      "                           SGD:  1.0 KiB\n",
      "              MeanSquaredError:  1.0 KiB\n",
      "                  MinMaxScaler:  1.0 KiB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d1590-e110-4009-95e6-8cdddccef848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
